<!DOCTYPE HTML>
<!--
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>

<head>
	<title>Jiuniu Wang | PhD Student </title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<noscript>
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
	</noscript>
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
	<script src="js/jquery.min.js"></script>
	<script src="js/skel.min.js"></script>
	<script src="js/skel-layers.min.js"></script>
	<script src="js/init.js"></script>
	<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body class="landing">

	<!-- Header -->
	<header id="header">
		<ul class="icons">
			<li>
				<a href="https://scholar.google.com/citations?user=wcOO6hgAAAAJ&hl=en" class="icon fa-graduation-cap"></a>
			</li>
			<li>
				<a href="https://github.com/wangjiuniu" class="icon fa-github"></a>
			</li>
			<!--
			<li>
				<a href="https://twitter.com/" class="icon fa-twitter"></a>
			</li>
			<li>
				<a href="https://www.linkedin.com/" class="icon fa-linkedin"></a>
			</li>
			-->
		</ul>

		<nav id="nav">
			<ul>
				<li><a href="/" class="active">Home</a></li>
				<li><a href="/#two">Publications</a></li>
				<li><a href="https://blog.ruantang.top/">Blog</a></li>
				<li><a href="/#footer">Contact</a></li>
			</ul>
		</nav>
	</header>

	<!-- One -->
	<section id="one" class="wrapper style1">
		<div class="container 75%">
			<div class="row 200%">
				<div class="6u 12u$(medium)">
					<header class="major">
						<h2>Jiuniu Wang<br>(王九牛)</h2>
						<p>
							<div class="image rounded" style="margin-bottom: 1.5em;"><img src="images/wjn_photo.jpg" width="200" alt="" /></div>
						</p>
						<p>Joint PhD candidate</p>
						<p>City University of Hong Kong</p>
						<p>University of Chinese Academy of Sciences</p>
					</header>
				</div>
				<div class="6u$ 12u$(medium)">
					<p>Currently, I'm doing research on Distinctive Image Captioning with <a href="https://www.cs.cityu.edu.hk/~abchan/" target="_blank">Prof. Antoni B. Chan</a> at <a href="https://www.cs.cityu.edu.hk/" target="_blank">City University of Hong Kong</a>.</p>

					<p>I am a joint PhD student at the University of Chinese Academy of Sciences, advised by <a href="http://people.ucas.ac.cn/~0001014?language=en" target="_blank">Prof. Yirong Wu</a>. My current research interests are in computer vision, natural language processing, and deep neural networks.</p>

					<p>My former background is in Electrical Engineering (B.Sc. hons. 2016 at <a href="http://english.bit.edu.cn/" target="_blank">Beijing Institute of Technology</a>).
				</div>
			</div>
		</div>

		<div class="container 75%">
			<h3 style="text-align: center">News</h3>
			<ul>
				<li>03/2022: Our paper about Zero-Shot Learning is accepted by IJCV (International Journal of Computer Vision).</li>
				<li>03/2022: Our paper about distinctive image captioning is accepted by TPAMI (IEEE Transactions on Pattern Analysis and Machine Intelligence).</li>
				<li>03/2022: Our paper about Zero-Shot Learning is accepted by CVPR 2022.</li>
				<li>07/2021: One paper accepted by ACM MM 2021 as <span style="font-weight: bold; color: #DC143C">Oral</span>!</li>
				<li>09/2020: One paper accepted by NeurIPS 2020!</li>
				<li>08/2020: One paper accepted by BMVC 2020!</li>
				<li>07/2020: One paper accepted by ECCV 2020 as <span style="font-weight: bold; color: #DC143C">Oral</span>!</li>
				<li>02/2020: Two paper accepted by KBS (Knowledge-based Systems).</li>
				<li>01/2020: One paper accepted by JSTSP (IEEE Journal of Selected Topics in Signal Processing).</li>
				<li>09/2019: I get to City University of Hong Kong as a joint PhD student, working with Prof. Antoni B. Chan.</li>
				<li>...</li>
				
			</ul>
		</div>
	</section>

	<!-- Two -->
	<section id="two" class="wrapper style2">
		<div class="container 75%">
			<h2 style="text-align: center">Selected Publications</h2>

<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/TPAMI22.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>On Distinctive Image Captioning via Comparing and Reweighting</h4>
<!--						<p>IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI, 2022</p>-->
					</header>
					<p><span style="text-decoration: underline;">Jiuniu Wang</span>, Wenjia Xu, Qingzhong, Antoni B. Chan. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022,
						[<a href=''>PDF</a>]. </p>
				</div>
			</div>


<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/APN_IJCV.png" width="220" alt="" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Attribute Prototype Network for Any-Shot Learning</h4>
<!--						<p>International Journal of Computer Vision, IJCV, 2022</p>-->
					</header>
					<p>Wenjia Xu, Yongqin Xian, <span style="text-decoration: underline;">Jiuniu Wang</span>, Bernt Schiele, Zeynep Akata. International Journal of Computer Vision (IJCV) 2022,
							 [<a href='https://wenjiaxu.github.io/APN-ZSL/'>Project Page</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/VGSE.png" width="220" alt=""/></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Visually-Grounded Semantic Embeddings for Zero-Shot Learning</h4>
						<p>IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2022</p>
					</header>
					<p>Wenjia Xu, Yongqin Xian, <span style="text-decoration: underline;">Jiuniu Wang</span>, Bernt Schiele, Zeynep Akata,
						[<a href='https://arxiv.org/abs/2203.10444'>PDF</a>, <a href='https://github.com/wenjiaXu/VGSE'>Code</a>]. </p>
				</div>
			</div>


			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/ciderbtw.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets</h4>
						<p>Proposing new metric for distinctiveness and new training strategy for distinctive image captioning. </p>
					</header>
					<p><span style="text-decoration: underline;">J Wang</span>, W Xu, Q Wang, A B. Chan, <span style="font-weight: bold">Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets</span>,
						ECCV (2020) <span style="font-weight: bold; color: #DC143C">Oral</span>,  [<a href='https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460358.pdf'>PDF</a>, <a href='https://wenjiaxu.github.io/ciderbtw/'>Project Page</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/APN.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Attribute Prototype Network for Zero-Shot Learning</h4>
						<p>A ZSL network that can learn general attribute prototypes for various images.</p>
					</header>
					<p>W. Xu, Y. Xian, <span style="text-decoration: underline;">J. Wang</span>, Z. Akata, B. Schiele, <span style="font-weight: bold">Attribute Prototype Network for Zero-Shot Learning</span>, NeurIPS (2020), [<a href='https://arxiv.org/pdf/2008.08290.pdf'>PDF</a>, <a href='https://wenjiaxu.github.io/APN-ZSL/'>Project Page</a>]. </p>
				</div>
			</div>

<!--			<hr />-->
<!--			<div class="row 200%">-->
<!--				<div class="3u 4u(large) 12u$(medium)">-->
<!--						<div class="image rounded"><img src="images/BMVC2020_cover.png" width="180" alt="" style="border:none;" /></div>-->
<!--				</div>-->
<!--				<div class="9u$ 8u$(large) 12u$(medium)">-->
<!--					<header>-->
<!--						<h4>Neighbours Matter: Image Captioning with Similar Images</h4>-->
<!--						<p>Aggregating information over similar images is used to improve image captioning models.</p>-->
<!--					</header>-->
<!--					<p>Q Wang, <span style="text-decoration: underline;">J Wang</span>, A B. Chan, S Huang, H Xiong, X Li, D Dou, <span style="font-weight: bold">Neighbours Matter: Image Captioning with Similar Images</span>,-->
<!--						BMVC (2020),  [<a href='https://www.bmvc2020-conference.com/assets/papers/0342.pdf'>PDF</a>].</p>-->
<!--				</div>-->
<!--			</div>-->

			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/where.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Where is the Model Looking At --Concentrate and Explain the Network Attention</h4>
						<p>Investigating where is the model's attention when doing classification, and how can we guide the attention.</p>
					</header>
					<p>W. Xu, <span style="text-decoration: underline;">J Wang</span>, Y Wang, G Xu,  D Lin, Y Wu, <span style="font-weight: bold">Where is the Model Looking At --Concentrate and Explain the Network Attention</span>, (IEEE Journal of Selected Topics in Signal Processing),  [<a href='https://ieeexplore.ieee.org/abstract/document/9067082'>Link</a>, <a href='https://arxiv.org/abs/2009.13862'>PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/ASTRAL.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition</h4>
						<p>An adversarial trained method for Named Entity Recognition.</p>
					</header>
					<p><span style="text-decoration: underline;">J Wang*</span>, W. Xu*, X Fu, G Xu, Y Wu, <span style="font-weight: bold">ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition</span>, (Knowledge-based Systems), (* = equal contribution),  [<a href='https://www.sciencedirect.com/science/article/abs/pii/S0950705120302136'>Link</a>, <a href="https://arxiv.org/abs/2009.01041">PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/SRQA.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>SRQA: Synthetic Reader for Factoid Question Answering</h4>
						<p>A robust method for Question Answering. </p>
					</header>
					<p><span style="text-decoration: underline;">J Wang*</span>, W. Xu*, Y Wei, L Jin, Z Chen, G Xu, Y Wu, <span style="font-weight: bold">SRQA: Synthetic Reader for Factoid Question Answering</span>, (Knowledge-based Systems), (* = equal contribution), [<a href='https://www.sciencedirect.com/science/article/abs/pii/S0950705119306471'>Link</a>, <a href="https://arxiv.org/abs/2009.01630">PDF</a>].</p>
				</div>
			</div>

			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image rounded"><img src="images/NLPCC2018.png" width="180" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>A3net: Adversarial-and-attention network for machine reading comprehension</h4>
						<p>Learning to recover high resolution remote sening images.</p>
					</header>
					<p><span style="text-decoration: underline;">J Wang</span>, X Fu, G Xu, Y Wu, Z Chen, Y Wei, L Jin, <span style="font-weight: bold">A3net: Adversarial-and-attention network for machine reading comprehension</span>, NLPCC (2018) <span style="font-weight: bold; color: #DC143C">Oral</span>, [<a href='https://link.springer.com/chapter/10.1007/978-3-319-99495-6_6'>Link</a>, <a href="https://arxiv.org/abs/1809.00676">PDF</a>].</p>
				</div>
			</div>
			<hr />
			<p style="text-align:center;">For a full list, have a look at my <a href="https://scholar.google.com/citations?user=wcOO6hgAAAAJ&hl=en">Google Scholar</a> page.</p>
		</div>
	</section>


	<!-- Three -->
	<section id="three" class="wrapper style3 special">
		<div class="container 50%">

			<h2>Curriculum vitae</h2>
			<ul class="actions">
				<li><a href="CV_WangJiuniu.pdf" class="button alt big">English Version (Previous)</a></li>
			</ul>
			<ul class="actions">
				<li><a href="resume_wjn_chinese.pdf" class="button alt big">Chinese Version</a></li>
			</ul>
		</div>
	</section>


	<!-- Footer -->
	<footer id="footer">
		<div class="container">
			<h2>Get in touch</h2>
			<p><span style="font-weight: bold">wangjiuniu [AT] GMAIL [DOT] COM</span><br /> City University of Hong Kong<br />University of Chinese Academy of Sciences</p>
			<p></p>
			<ul class="icons">
				<li>
					<a href="https://scholar.google.com/citations?user=wcOO6hgAAAAJ&hl=en" class="icon fa-graduation-cap"></a>
				</li>
				<li>
					<a href="https://github.com/wangjiuniu" class="icon fa-github"></a>
				</li>
				<!-- <li>
					<a href="https://twitter.com/wenjia43411575" class="icon fa-twitter"></a>
				</li>
				<li>
					<a href="https://www.linkedin.com/in/%E6%96%87%E5%98%89-%E8%AE%B8-440867139/" class="icon fa-linkedin"></a>
				</li> -->
			</ul>
			<ul class="copyright">
				<li>&copy; 2022 Jiuniu Wang</li>
				<!-- <li>Design: <a href="http://templated.co">TEMPLATED</a></li> -->
			</ul>
		</div>
	</footer>

</body>

</html>
